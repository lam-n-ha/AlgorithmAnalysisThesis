\chapter{Code Components}

To in order to perform algorithm analysis with JuPE, the user need to follow the folliowing 3 steps:
\begin{enumerate}
	\item Choose from a supported list the class of function to be optimized.
	\item Define an algorithm to be analyzed .
	\item Specify a performance measure.
  \end{enumerate}
 
\begin{figure}[hbtp]
    \caption{Analysis Example}
    \label{ex_analysis}
	\begin{lstlisting}[mathescape]
	m,L = 1,10
	$ \alpha $ = 2/(L+m)
	@algorithm begin

		f = DifferentiableFunctional{R$ ^n $}()
		xs = first_order_stationary_point(f)
		f' $ \in $ SectorBounded(m, L, xs, f'(xs))

		x0 = R$ ^n $()
		x1 = x0 - $ \alpha $*f'(x0)

		x0 => x1

		performance = (x1-xs)^2
	end

	@show rate(performance)
\end{lstlisting}
\end{figure}

In the example code, the user while using JuPE's provided macro to simplify the input process:
\begin{itemize}
	\item Defined the class of function f and its gradient f' by calling one of the provided functions, in this case 1 smooth 10 strong convex functions.
	\item Set the global minimum goal as a stationary point $ x_s $
	\item Defined an initial state $ x_0 $ and specified the algorithm with which the state is updated using algebra - gradient descent with a step size 2/11 in this example.
	\item Set the performance measure as the norm distance between the updated point and the goal $ (x_1 - x_s)^2 $ .
\end{itemize}

With the calling of the "rate" function, JuPE derives every necessary input from the performance measure and performs analysis automatically to return a rate of 0.6687164306640625, which can be seen in Figure~\ref{ex_result}. This means for the provided algorithm and every function in the class, the convergence rate of the performance measure is guaranteed to match or exceed the result worst-case guarantee rate.
 
\begin{figure}[hbtp]
    \caption{Analysis result}
    \label{ex_result}
\begin{lstlisting}
rate(performance) = 0.6687164306640625
\end{lstlisting}
\end{figure}

JuPE performs algorithm analysis by following the set of instructions presented in section 3 to create and solve an optimization problem and derive a performance certification. Implenmenting a mathematical procedure as code presents a list of challenges which includes being able to understand and differentiate between variables, represent concepts such as gradients or states, or formulating and solving a convex optimization problem, while keeping the users' interaction with the program simple. This chapter goes into the code that constitutes JuPE and enables these functionalities.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Expressions}

Expressions are data structures acting as the smallest building block upon which every other concepts are built. An expression data structure contains the following fields:
\begin{description}
	\item[Label] When an expression is defined, the variable name used is stored in the expression as a string
	\item[Value] Stores the value or decomposition of an expression.
	\item[Constraints] When a constraint is applied to an expression, such as an expression being positive or negative semidefinite, the constraint is stored in the 'constraints' field.
	\item[Oracles] When an expression is defined by sampling one or multiple oracles, the oracles used are stored in the expression data structure
	\item[Next] When a state is defined as the 'next' state of another state, it is stored in the original state under the 'next' field.
 \end{description}

\subsection*{Value and Decomposition}
Each expression contains in its 'value' field either a scalar value, a vector value, or a decomposition dictionary. Depending on the content of the 'value' field, expressions can be categorized as:
\begin{description}
	\item[Variable expressions] an expression defined to be in a field. Its value is empty and its decomposition is itself.
\begin{figure}[hbtp]
	\caption{Example of a variable expression}
	\label{ex_variable}
		\begin{lstlisting}[mathescape]
	x0 = R$^n$()
	@show(x0)
	x0 = Variable{R$^n$}

	Vector in R$^n$
		Label: Variable{R$^n$}
		Oracles: LinearFunctional{R$^n$}
		Associations: Dual => LinearFunctional{R$^n$}	
		\end{lstlisting}
\end{figure}
	\item[Decomposition expressions] formed by performing algebra on other expressions. Its value is a decompostion data structures containing how many of each variable expressions forms the decomposition expression.

\begin{figure}[hbtp]
	\caption{Example of a decomposition expression}
	\label{ex_decomposition}
		\begin{lstlisting}[mathescape]
	decomposition_exp = (x0-xs)$^2$
	@show decomposition_exp 
	decomposition_exp = -<x0,xs> + |x0|$^2$ - <xs,x0> + |xs|$^2$

	Scalar in R
		Decomposition: -<x0,xs> + |x0|$ ^2 $ - <xs,x0> + |xs|$ ^2 $
		\end{lstlisting}
\end{figure}

In the 
\end{description}

\subsection*{Fields}
In example \ref{ex_variable}, expression 'x0' is defined to be in field R$^n$, a field pre-defined in JuPE which encompasses n-dimensional.

\subsection*{Algebra}
Expressions in JuPE belong in an inner product space, which is a set of elements that can be vectors or numbers. Inner product spaces allow a list of operations, all of which are supported by JuPE, including:
\begin{description}
	\item[Addition or subtraction between expressions] Vectors and numbers can be added together in an inner product space. In an addition operation, if both expressions of the operation posess a 'value', they are added to create the value of a new resulting expression. Otherwise, the result is a new expression is created whose decomposition is the merging of the expressions being combined's decompositions.
	\item[Multiplication or division between an expression and a scalar] This operation scales the value or decomposition of an expression by the scalar value.
	\begin{figure}[hbtp]
		\caption{Example of addition, subtraction and scalar operation}
		\label{ex_algebra1}
		\begin{lstlisting}[mathescape]
	@algorithm begin
		x0 = R$^n$()
		y0 = R$^n$()
		a = x0-2*y0
		b = a+2*x0
	end
	@show(a)
	a = a

	Vector in R$^n$
		Label: a
		Decomposition: -2 y0 + x0
		Associations: Dual => a*
	@show(b)
	b = b
	
	Vector in R$^n$
		Label: b
		Decomposition: -2 y0 + 3 x0
		Associations: Dual => b*
	
		\end{lstlisting}
	\end{figure}

	\item[Inner product operation between two vectors] In an inner product space, the inner product of two vectors result in a scalar.
	\item[Squared norm] An expression of the normed vector vpace type can be squared to produce a an inner product space expression.
	\begin{figure}[hbtp]
		\caption{Example of an inner product between two vectors and norm of vector}
		\label{ex_innerandnorm}
		\begin{lstlisting}[mathescape]
	@algorithm begin
		inner = x0'*y0
		norm = x0^2
	end
	@show(inner)
	inner = <y0,x0>

	Scalar in R
		Label: <y0,x0>
		Oracles: x0*
	@show(norm)
	norm = |x0|$^2$
	Scalar in R
		Label: |x0|$^2$
		Oracles: x0*
		\end{lstlisting}
	\end{figure}
\end{description}

\section{Oracles}
As JuPE perform analysis over sets of functions using only constraints on the \( \nabla (f) \) block of, the block can be treated as a blackbox. In JuPE, these blackboxes are represented by oracles, data strucutres containing the relation and constraint information between expressions. Each oracle represent a class of function and can only exist if there exist interpolation conditions for said class. Oracles can be sampled at an expression to return another expression, establishing the relation information between the two expressions. As an oracle is sampled, JuPE uses the set of interpolation conditions to create every constraints on the two expressions.  In \ref{ex_analysis}, by calling the SectorBounded function, an oracle containing the interpolation conditions for 1 strong 10 smooth convex functions is created and labeled f', and the oracle is sampled at points xs and x0 by defining f'(xs) and f'(x0) inside the labeling macro.

\subsection*{Inner product oracle}
Different from other algebraic operations supported by JuPE, the inner product is derived by creating an oracle of one vector and sampling it at the other vector of an operation, returning a new variable expression. As both the transpose of a vector, which is used to calculate the inner product, and the gradient of a function uses the notation " ' ", oracles are used to assist in the formation of inner product expressions. In this case, the oracle is not based on any class of function and therefore attribute no constraint to the vector being sampled.

\section{States}
JuPE represents the states of an algorithm using expressions. As the user inputs the algorithm being analyzed, an initial state is created and an updated state is defined as some algebraic combination of the initial state and the gradient. The relationship between a state and its next state can be defined using the "=>" operation inside the labeling macro, as can be seen in \ref{ex_analysis}, and the next state is stored in the "next" field of a state expression.

%Variable expressions that make up the next state must be in the same field as those of the previous state.

\section{Label}
JuPE uses macro to keep the process of providing inputs to the program simple. As some of the programming rules of programming might be difficult to navigate for users who might not be used to programming, in order to make the process of using JuPE as accessible as possible, JuPE's macro:
\begin{description}
	\item[Describe] When an expression is referenced, JuPE will describe the expression and any relevant field without the user having to access it.
	\item[Define] During the inputing process, users can define a new expression or oracle with only one line specifying its trait, instead of the usual steps of declaring a new object and filling in its fields that typically exist in programming. The macro will calls the necessary functions to create the object, assign every relevant field as well as updating every  object associated with the one being created.
\end{description}

\section{Constraints}
As part of the analysis process, JuPE uses the interpolation conditions of the class of function inputted by the user to create constraints similar to section 3.2. To support constraints, JuPE uses data structures that include the expression constrained and one of the supported sets of values defined by the constraints.

When an oracle is sampled, a set of constraints on the expression being sampled and the result of the sample - the input and output of the black box - is created, and constraints are added as the oracle is sampled at more than one expression. For each constraint, the constraint is added to each variable expressions associated with it. The figure below shows the constraints created by the oracle in \ref{ex_analysis}:

\begin{figure}[hbtp]
	\caption{Example of oracle created constraint}
	\label{ex_orc_constraints}
	\begin{lstlisting}[mathescape]
vars, cons, orcs = variables_constraints_oracles(performance)
cons
	Set of constraints with 3 elements:
		0 $<=$ 1.1 <$\nabla $f(x0),x0> + 2.0 <xs,x0> - 2.0 |x0|$^2$ + 1.1 <x0,$\nabla $f(x0)> - 2.0 |xs|$^2$ - 1.1 <xs,$\nabla $f(x0)> + 2.0 <x0,xs> - 0.2 |$\nabla $f(x0)|$^2$ - 1.1 <$\nabla $f(x0),xs>
		0 $<=$ R[|x0|$^2$ <xs,x0>; <x0,xs> |xs|$^2$]
		0 $<=$ R[|x0|$^2$ <$\nabla $f(x0),x0> <xs,x0>; <x0,$\nabla $f(x0)> |$\nabla $f(x0)|$^2$ <xs,$\nabla $f(x0)>; <x0,xs> <$\nabla $f(x0),xs> |xs|$^2$]
	\end{lstlisting}
\end{figure}

In addition to being created by sampling oracles, constraints can also be defined by users. When analyzing any algorithm, constraints can be added to the initial condition of the algorithm. Any constraints added by the user is included in the formation of the optimization problem used to derive the performance bound.

\begin{figure}[hbtp]
	\caption{Example of user added constraint}
	\label{ex_user_constraints}
	\begin{lstlisting}[mathescape]
	@algorithm begin
		(x0-xs)^2 $<=$ 1
	end
	\end{lstlisting}
\end{figure}
\section{Performance measure}
Part of JuPE's required inputs is the performance measure, the convergence rate of which JuPE finds the worst-case guarantee through algorithm analysis. In \ref{ex_analysis}, the performance measure is set as $ (x_0 - x_s) ^2 $, which is the norm or distance between the initial point and the goal, which means the convergence rate guarantee returned is that of the distance between the point updated using gradient descent after each iteration $ x_k $ and the goal $ x_s $.
\section{JuMP}
 
\section{Lyapunov function formulation}