\chapter{Discussion And Conclusion} \label{chapter:conclusion}

\subsection*{Discussion and Future work}

In a development version of the \texttt{AlgorithmAnalysis.jl} package which uses the SCS \cite{SCS} solver instead of the Mosek solver, we observed that the program produced inaccurate result in the analysis of TMM over $L$-smooth $m$-strongly convex functions for condition numbers $L/M$ between one and two. In these cases, the program returned a performance guarantee faster than the algorithm's theoretical limit, which is set at $1-\sqrt{m/L}$. This behavior ceased when we switch to the Mosek solver.

While the current experimental validations demonstrate that the \texttt{AlgorithmAnalysis.jl} package accurately generates worst-case performance guarantees for several prominent first-order optimization methods, we can explore other methods to test compatibility. Future work should can include systematic testing and verifying the package against a wider range of first-order unconstrained optimization algorithms. This extended analysis will further confirm the robustness of the package's implementation of the Lyapunov approach and highlight any potential limitations.

An area of the package that can be expanded in the future is the analysis of the primal-dual algorithm used to optimize constrained problems. These problems are different from the unconstrained type we have looked at so far in that the minimizer $x_s$ has to satisfy a constraint $Ax = b$ where $A$ is an abstract matrix. In the Lyapunov-based approach in \cite{primaldual}, this constraint would be characterized by bounds on the value of $A$, which introduces the values of the bounds on $A$ as the third input in our analysis, on top of the algorithm and the function class. Similar to a function class, the matrix $A$ would be represented in the analysis by interpolation conditions.

The SVD-based transformation used by the approach in \cite{primaldual} also separates each state vector into two vectors in different vector spaces. These two vectors would each have its own corresponding gradient while together samples the function to create one function value. In order to automate the creation of these elements and their constraints, it requires oracles different from the one input one output ones we have used for the analysis of GD, FG, HB, and TMM --- The function oracle for PD would have two vector expressions as input and one scalar expression as output, while the corresponding gradient oracle would have the same input and two vector expression outputs. The necessary interpolation conditions and oracle types to analyze PD have been implemented, however the package is unable to derive an  performance guarantee accurate to those presented in \cite{primaldual}. Possible future work can include debugging the code that implements analysis of PD. 

\subsection*{Concluson}

This thesis has presented the implementation of algorithm analysis using Lyapunov functions in the Julia programming language. \texttt{AlgorithmAnalysis.jl} provides a robust and accessible platform for analyzing first-order optimization algorithms to derive a worst-case performance guarantee. The package adapts the Lyapunov approach to better suit software implementation, establishes a domain-specific language that substantially simplifies the user experience, and created a systemic and automated way to apply interpolation conditions and Lyapunov function-based optimization problems. Ultimately, the package bridges the gap between theoretical performance analysis and practical optimization tasks, making rigorous algorithm analysis accessible to a broader audience of researchers and developers.

The package can be found in the AlgorithmAnalysis.jl GitHub repository at https://github\allowbreak .com/vanscoy/AlgorithmAnalysis.jl.