\chapter{Literature Review}\label{chapter:literature}

In recent years, numerous studies have compared the performance of optimization algorithms, particularly in machine learning and deep learning applications. These comparisons typically evaluate convergence speed, accuracy, and robustness across diverse models and datasets. In \cite{adam}, the AdaM (Adaptive Moment Estimation) algorithm was introduced, combining the advantages of two popular methods: AdaGrad and RMSProp. The authors demonstrated Adam's efficiency over existing algorithms through extensive experiments on various machine learning tasks, including training deep neural networks, where it showed faster convergence and better performance.

Despite its empirical successes, however, subsequent work in \cite{adam2} revealed that Adam may fail to converge on simple quadratic problems under certain conditions. These findings highlight the importance of complementing empirical evaluations with rigorous theoretical analyses to fully understand the behavior of optimization algorithms. They demonstrate the benefit of robust analytical frameworks, such as the one proposed in this thesis, to provide deeper theoretical guarantees and enhance the reliability of algorithmic performance assessments.

Among the various approaches developed for automated algorithm analysis aimed at guaranteeing minimum performance criteria, one of the most influential frameworks is the Performance Estimation Problem (PEP). Initially proposed by Drori and Teboulle in 2014, the PEP framework introduced a systematic method to evaluate the worst-case performance of optimization algorithms by translating performance analysis into an optimization problem itself, specifically a semidefinite program (SDP) \cite{drori2012}. By modeling a given class of optimization problems using constraints, the authors reformulated the analysis task as a convex optimization problem. This enabled the computation of exact or numerically tight worst-case performance guarantees by solving an SDP numerically, which was pioneering in providing robust theoretical performance guarantees. The shift away from manually derived analytical proofs toward automated computational methods is also significant, as it allows the use of computers in the process of deriving algorithms's worst-case performance bounds.

Subsequent contributions significantly expanded upon this foundational approach. Taylor, Hendrickx, and Glineur further developed the PEP methodology by introducing closed-form necessary and sufficient interpolation conditions for certain function classes, such as smooth strongly convex functions, thereby providing a finite representation of these function classes in the SDP \cite{pepit}.

% The Python library PEPit implements the PEP method into a software package as a practical way of using the framework, providing a high-level interface for formulating and solving performance estimation problems. PEPit allows users to specify an algorithm and its target function class using a simple, declarative syntax, internally it automatically constructs the corresponding semidefinite program that characterizes the worst-case behavior of the algorithm and solves it using an appropriate SDP solver. This automation significantly reduces the technical barrier to applying PEP, enabling researchers and practitioners to obtain certified performance bounds without manually deriving interpolation conditions or constraint formulations. It also comes with built-in support for numerous standard algorithms (such as gradient descent, fast gradient, and proximal methods) and common function classes, including smooth convex, strongly convex, and composite objective structures, allowing users to test and compare different methods with minimal setup.

Moreover, their work culminated in the creation of PEPit, an open-source Python-based software package designed specifically as a high-level, streamlined interface for formulating and solving performance estimation problems. PEPit allows users to specify an algorithm and its target function class using a simple, declarative syntax. Internally, it automatically constructs the corresponding semidefinite program using the PEP method and solves it using an appropriate SDP solver. This automation significantly reduces the technical barrier to applying PEP, enabling researchers and developers to obtain certified performance bounds without manually deriving interpolation conditions or constraint formulations. It also comes with built-in support for numerous standard algorithms (such as gradient descent, fast gradient, and proximal methods) and common function classes, including smooth convex, strongly convex, and composite objective structures. This allows users to test and compare different methods. This ease of use and versatility or PEPit have significantly contributed to its prominence as a tool in both academic research and practical algorithm development.

Both the original formulation by Drori and Teboulle and the subsequent refinements implemented in PEPit share their motivations and techniques with Lyapunov function-based analysis. Specifically, both approaches rely on constructing structured semidefinite programming formulations to rigorously quantify worst-case algorithm performance. However, the Lyapunov approach differs in that it uses an energy-based decreasing Lyapunov function to certify whether a performance level, defined as the convergence rate of the algorithm, can be guaranteed. 

% Of the approaches to automated algorithm analysis to analyzing algorithms which guarantee an algorithm's minimum performance, an influential framework is Performance Estimation Problem (PEP). In 2014, Drori and Teboulle first introduced the method of representing a class of function with constraints, reformulating the problem of analyzing an optimization method into a semidefinite program (SDP) \cite{drori2012}. The paper coined the term PEP and showed that by solving a convex semidefinite problem, a worst-case numerical bound on an algorithm's performance solving that class of function can be derived. This approach shares key motivations with interpolation-based Lyapunov analysis: both aim to provide tight, mathematically proven performance guarantees, and both rely on semidefinite formulations to model algorithm behavior within structured function classes.Taylor, Hendrickx and Glineur built upon this work by introducing the ideas of creating a finite representation for a class of smooth strongly convex functions using closed-form necessary and sufficient conditions \cite{pepit}.

% The Python library PEPit implements the PEP method into a software package as a practical way of using the framework, providing a high-level interface for formulating and solving performance estimation problems. PEPit allows users to specify an algorithm and its target function class using a simple, declarative syntax, internally it automatically constructs the corresponding semidefinite program that characterizes the worst-case behavior of the algorithm and solves it using an appropriate SDP solver. This automation significantly reduces the technical barrier to applying PEP, enabling researchers and practitioners to obtain certified performance bounds without manually deriving interpolation conditions or constraint formulations. It also comes with built-in support for numerous standard algorithms (such as gradient descent, fast gradient, and proximal methods) and common function classes, including smooth convex, strongly convex, and composite objective structures, allowing users to test and compare different methods with minimal setup.

% This work culminated in the implementation of PEP as a software package introducing a way to perform analyse an algorithm to derive its performance bound over a function class in the form of a guarantee that after a fixed number of iterates, how close the last iterate is to the goal. This implementation created PEPit \cite{pepit}, a Python package, and PESTO \cite{pesto}, a corresponding MATLAB toolbox. PESTO and PEPit follows the PEP methodology and first presented an automatic way to analyze gradient-based algorithms: Given an algorithm and problem class from a supported list, the programs can provide a guaranteed minimum convergence rate of the algorithm for every problems in the class.

In \cite{iqc}, Megretski and Rantzer demonstrated how integral quadratic constraints (IQCs) can be used to unify and simplify the analysis of system stability and performance. The paper introduced the idea that optimization algorithms can be interpreted as a dynamical system in which the gradient of the objective function --- a complex system --- can be represented with IQCs. This idea leverages tools from \textit{robust control} similar to the Lyapunov-based approach we are implementing. Through this interpretation, the problem of analyzing algorithms' performance is transformed into a robust control problem, and analyzing the performance of the optimization algorithm is equivalent to analyzing the stability of the corresponding dynamical system. The first paper to apply IQCs from robust control to analyze the performance of optimization algorithms is~\cite{lessard2016}, a highly influential paper in this area. While both~\cite{lessard2016} and Drori and Teboulle's PEP method derive an SDP the solution of which guarantees precise bounds on the convergence rate of first-order algorithms, a major drawback of the PEP method was that the SDP scales in size with the number of iterations the algorithm is run, increasing the computational cost and time it requires so perform analysis. In~\cite{lessard2016}, authors Lessard, Recht, and Packard demonstrate that by using Lyapunov functions, a bound on an algorithm's convergence rate which holds for all iterations can be found by deriving a small and fixed-size SDP.

In \cite{tutorial}, the authors Bryan Van Scoy and Laurent Lessard present a Lyapunov-function-based approach to analysis, which transforms the analysis problem into a robust control problem, similar to the IQC method, and uses interpolation conditions to describe the complex system that is the gradient of the smooth strongly convex function class, similar to the PEP method. The method then forms a convex optimization problem of finding a Lyapunov function that proves the algorithm converges at a certain rate, the feasibility of which establishes whether a convergence rate can be guaranteed for the given algorithm and problem class. The problem of finding the fastest guaranteed rate is then to simply search over convergence rates between zero and one for the fastest one that can be guaranteed. The Lyapunov function-based approach used by the \texttt{AlgorithmAnalysis.jl} package modifies how the Lyapunov function is formed compared to the approach presented in \cite{tutorial} to better facilitate its implementation into a software program, and will be discussed in \cref{chapter:lyapunov}.

While \cite{tutorial} and this thesis focus on the optimization of unconstrained first-order methods, another work in the field of automatic analysis of optimization algorithms using Lyapunov function is the work in \cite{primaldual}, which focuses on linearly constrained optimization problems. These problems are in the form of:

\begin{subequations}\label{linearly_constrained}
    \begin{align}
      \textrm{minimize} &\quad f(x) \\
      \textrm{subject to} &\quad Ax = b 
    \end{align}
  \end{subequations} 

In \cite{primaldual}, the author defines $A$ in \eqref{linearly_constrained} as an abstract matrix whose singular values are bound by an upper and lower value. The authors proposed a framework for the automatic analysis of primal-dual algorithms \cite{primaldualalgo} used to solve linearly constrained convex optimization problems. The primal dual algorithm differs from those used for unconstrained problems in that it uses a transformation based on a compact singular value decomposition (SVD) of the constraint matrix $A$. This allows the algorithm's dynamics to be separated into components that are affected and unaffected by the constraints, simplifying the structure of the problem and enabling a more systematic application of Lyapunov functions to certify convergence guarantees. While the separation of the state iterate and the introduction of another nonlinearity makes the analysis of constrained problems different from the unconstrained case, the overall methodology is similar to the Lyapunov-based framework presented in \cite{tutorial} in its use of interpolation conditions and matrix inequalities to automatically derive worst-case performance bounds. This work demonstrates that the Lyapunov function-based approach can perform automated analysis for constrained as well as unconstrained problems.

The approaches to automated algorithm analysis in the literature presented above can be broadly categorized into two main types, the optimization-based PEP approach, which was implemented into PEPit, and the control approach, which has not been implemented into a computer program. The main contribution of this thesis is the development of \texttt{AlgorithmAnalysis.jl}, aims to be a robust framework for the analysis of iterative first-order algorithms similar to PESTO and PEPit. However, it would apply the Lyapunov function-based approach instead of the PEP method.

We will also show that by developing it as a domain-specific language inside the Julia programming language, we enable users to describe optimization algorithms at a high level, providing a more intuitive way of defining the method to be analyzed compared to PEPit. By being a domain-specific language, the package would also allow a systematic representation of algorithmic components such as iterates, gradients, and function oracles, simplifying the understanding of both the analysis result and the Lyapunov-based approach compared to PEPit. The package does this while similar to PEPit automating the generation of interpolation conditions and every other component needed to derive a performance guarantee. This means \texttt{AlgorithmAnalysis.jl} would require the user only to define the algorithm they wish to analyze and the function class, lowering the barrier to entry for non-experts and facilitating rapid experimentation in algorithm design.