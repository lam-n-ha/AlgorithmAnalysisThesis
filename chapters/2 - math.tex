\chapter{Literature Review}\label{chapter:literature}

In recent years, numerous studies have been conducted comparing the performance of optimization algorithms, particularly in machine learning and deep learning contexts. These comparisons often focus on convergence speed, accuracy, and robustness across various models and datasets. In \cite{adam}, Kingma and Ba presented the Adam (Adaptive Moment Estimation) algorithm. In order to prove its efficiency improvement above existing algorithms, the authors designed and conducted experiments where they are used to solve popular machine learning models and recorded the convergence rate of each. The result of these experiments provided emperical evidence that Adam performed better compared to its peers and gave a general idea of Adam's performance.

\comment{While Adam is a very popular algorithm in machine learning and has been shown to have good empirical performance, \href{https://link.springer.com/chapter/10.1007/978-3-030-30484-3_20}{this paper} shows that it can actually not converge on simple problems, highlighting the need for better analysis tools.}

On the other hand, there exist in the literature approaches to performing algorithm analysis. In 2014, Drori and Teboulle first introduced the method of representing a class of function with constraints, reformulating the problem of analyzing an optimization method into a semidefinite program (SDP) whose size is proportionate with the number of iterations the algorithm is run. \cite{drori2012} \comment{(citations should appear inside the period)}. The paper coined the term Performance Estimation Problem (PEP) and showed that by solving a convex semidefinite problem (SDP) \comment{(only define acronyms once, unless perhaps the definitions are really far apart)}, a worst-case numerical bound on an algorithm's performance solving that class of function can be derived. Taylor, Hendrickx and Glineur built upon this work by introducing the ideas of creating a finite representation for a class of smooth strongly convex functions using closed-form necessary and sufficient conditions \comment{(citation?)}. This work culminated in a way to perform algorithm analysis to derive the performance bound in the form of a guarantee that after a finxed \comment{(spelling)} number of iterates, how close the last iterate is to the goal.

In \cite{iqc}, Megretski and Rantzer demonstrated how integral quadratic constraints (IQCs) can be used to unify and simplify the analysis of system stability and performance. The paper shows how a complex system can be described using certain IQCs and presents a stability theorem for systems described by IQCs. \comment{Need to expand on how this is related to algorithm analysis. The idea is to interpret optimization algorithms as dynamical systems in which the gradient of the objective function is constrained to be in some class. This is then a \textit{robust control} problem, and analyzing the performance of the optimization algorithm is equivalent to analyzing the stability of the corresponding dynamical system. IQCs are then one tool from robust control that can be applied to study robust stability. Another highly influential paper in this area is~\cite{lessard2016}, which was the first paper to apply IQCs from robust control to analyze the performance of optimization algorithms.}

Computer programs have been developed to perform algorithm analysis using the PEP methods, which are PESTO \cite{pesto}, a MATLAB toolbox, and PEPit \cite{pepit}, a Python package. The program is able to perform algorithm analysis and generate a worst-case performance guarantee for algorithms and function classes from a supported list. PESTO and PEPit follows the PEP methodology and first presented an automatic way to analyze gradient-based algorithms. 

JuPE implements the approach presented in \cite{tutorial}, which uses IQCs to represent the gradient of the algorithm and transforms the problem of deriving a performance guarantee to a convex SDP similar to the PEP approach. However, this approach instead uses Lyapunov functions to create a small and fixed size SDP, unlike that created by the PEP approach which grows in size for each iteration an algorithm is run \comment{(describe this at the end of the previous paragraph to motivate the Lyapunov analysis)}, and proves that the performance measure inputted \comment{(avoid ``inputted'')} by the users decreases at a guaranteed rate throught out the optimizing process.

The main contribution of this thesis paper is to create a computer program named JuPE \comment{(see \href{https://pkgdocs.julialang.org/v1/creating-packages/\#Package-naming-rules}{here} for the naming rules of Julia packages, in particular, the first two rules are to avoid jargon and avoid prefixing the package name with ``Ju'')} similar PESTO and PEPit that aims to provide an accessible and fast way to analyze the performance of first-order methods for a guaranteed convergence rate. By developing a domain-specific compiler inside the Julia programming language, JuPE simplifies the process of defining an optimization algorithm, provides a systemic way to represent abstract concepts such as algorithm iterate or the gradient of an abstract function, and make accessible the analysis of optimization algorithms.