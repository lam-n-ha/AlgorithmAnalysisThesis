\chapter{Literature Review}\label{chapter:literature}

In recent years, numerous studies have been conducted comparing the performance of optimization algorithms, particularly in machine learning and deep learning contexts. These comparisons often focus on convergence speed, accuracy, and robustness across various models and datasets. In \cite{adam}, Kingma and Ba presented the Adam (Adaptive Moment Estimation) algorithm. In order to prove its efficiency improvement above existing algorithms, the authors designed and conducted experiments where they are used to solve popular machine learning models and recorded the convergence rate of each. The result of these experiments provided emperical evidence that Adam performed better compared to its peers and gave a general idea of Adam's performance.

While the emperically proven performance of Adam has made it one of the most popular algorithms in machine learning, in \cite{adam2}, it is proved that under specific conditions, Adam is unable to converge on simple quadratic problems. This is something observational analysis did not demonstrate, highlighting its shortcomings and need for better analysis tools.

Of the approaches to automated algorithm analysis to analyzing algorithms which guarantee an algorithm's minimum performance, an influential framework is Performance Estimation Problem (PEP). In 2014, Drori and Teboulle first introduced the method of representing a class of function with constraints, reformulating the problem of analyzing an optimization method into a semidefinite program (SDP) \cite{drori2012}. The paper coined the term PEP and showed that by solving a convex semidefinite problem, a worst-case numerical bound on an algorithm's performance solving that class of function can be derived. This approach shares key motivations with interpolation-based Lyapunov analysis: both aim to provide tight, mathematically proven performance guarantees, and both rely on semidefinite formulations to model algorithm behavior within structured function classes.Taylor, Hendrickx and Glineur built upon this work by introducing the ideas of creating a finite representation for a class of smooth strongly convex functions using closed-form necessary and sufficient conditions \cite{pepit}.

The Python library PEPit implements the PEP method into a software package as a practical way of using the framework, providing a high-level interface for formulating and solving performance estimation problems. PEPit allows users to specify an algorithm and its target function class using a simple, declarative syntax, internally it automatically constructs the corresponding semidefinite program that characterizes the worst-case behavior of the algorithm and solves it using an appropriate SDP solver. This automation significantly reduces the technical barrier to applying PEP, enabling researchers and practitioners to obtain certified performance bounds without manually deriving interpolation conditions or constraint formulations. It also comes with built-in support for numerous standard algorithms (such as gradient descent, fast gradient, and proximal methods) and common function classes, including smooth convex, strongly convex, and composite objective structures, allowing users to test and compare different methods with minimal setup.

This work culminated in the implementation of PEP as a software package introducing a way to perform analyse an algorithm to derive its performance bound over a function class in the form of a guarantee that after a fixed number of iterates, how close the last iterate is to the goal. This implementation created PEPit \cite{pepit}, a Python package, and PESTO \cite{pesto}, a corresponding MATLAB toolbox. PESTO and PEPit follows the PEP methodology and first presented an automatic way to analyze gradient-based algorithms: Given an algorithm and problem class from a supported list, the programs can provide a guaranteed minimum convergence rate of the algorithm for every problems in the class.

In \cite{iqc}, Megretski and Rantzer demonstrated how integral quadratic constraints (IQCs) can be used to unify and simplify the analysis of system stability and performance. The paper introduced the idea that optimization algorithms can be interpreted as a dynamical systems in which the gradient of the objective function --- a complex system --- can be constrained to be in some class using IQCs, making IQCs one tool from \textit{robust control} that can be applied to study robust stability. Through this interpretation, the problem of analyzing algorithms' performance is transformed into a robust control problem, and analyzing the performance of the optimization algorithm is equivalent to analyzing the stability of the corresponding dynamical system. The first paper to apply IQCs from robust control to analyze the performance of optimization algorithms is~\cite{lessard2016}, a highly influential paper in this area. While both~\cite{lessard2016} and Drori and Teboulle's PEP method derive an SDP the solution of which guarantees precise bounds on the convergence rate of first order algorithms, a major drawback of the PEP method was that the SDP scales in size with the number of iterations the algorithm is run, making the analysis of algorithms which. In~\cite{lessard2016}, authors Lessard, Recht, and Packard demonstrate by using Lyapunov functions, a bound on an algorithm's convergence rate can be found by deriving a small and fixed size SDP.

The AlgorithmAnalysis.jl package implements the algorithm analysis approach presented by Van Scoy and Lessard in \cite{tutorial}. This Lyapunov-based approach to analysis transforms the analysis problem into a robust control problem, similar to the IQC method, and uses interpolation conditions to describe the complex system that is the gradient of the smooth strongly convex function class, similar to the PEP method. The method then forms a convex optimization problem of finding a Lyapunov function that proves the algorithm converges at a certain rate, the feasibility of which establishes whether a convergence rate can be guaranteed for the given algorithm and problem class. The problem of finding the fastest guaranteed rate is then to simply search over convergence rates between 0 and 1 for the smallest one that can be guaranteed.

Another recent direction in the automatic analysis of optimization algorithms is the work in \cite{primaldual}, which extends Lyapunov-based techniques to the analysis of primal-dual methods for linearly constrained convex optimization problems.  Their approach uses a transformation based on a compact singular value decomposition (SVD) of the constraint matrix, allowing the algorithm's dynamics to be separated into components that are affected and unaffected by the constraints. This reformulation simplifies the structure of the problem and enables a more systematic application of Lyapunov functions to certify convergence guarantees. While the mathematical details differ from the unconstrained case, the overall methodology aligns with other interpolation-based Lyapunov frameworks in its use of convex function properties and matrix inequalities to automatically derive worst-case performance bounds. This work demonstrates the potential of automated analysis techniques beyond unconstrained settings and highlights the value of structural problem transformations in extending their applicability.

Similar to \cite{tutorial}, another way to use Lyapunov function to perform automated algorithm analysis have introduced to analyze optimization algorithms in the form of:
\begin{subequations}\label{linearly_constrained}
    \begin{align*}
      \textrm{minimize} &\quad f(x) \\
      \textrm{subject to} &\quad Ax = b 
    \end{align*}
  \end{subequations}
In, \cite{primaldual}, the authors proposed a framework for the automatic analysis of primal-dual algorithms used to solve linearly constrained convex optimization problems. Their approach uses a transformation based on a compact singular value decomposition (SVD) of the constraint matrix, allowing the algorithm's dynamics to be separated into components that are affected and unaffected by the constraints. This reformulation simplifies the structure of the problem and enables a more systematic application of Lyapunov functions to certify convergence guarantees. While the mathematical details differ from the unconstrained case, the overall methodology is similar with the Lyapunov-based framework presented in \cite{tutorial} in its use of convex function properties and matrix inequalities to automatically derive worst-case performance bounds. This work proves Lyapunov function-based automated analysis can be applied beyond unconstrained settings and a special case algorithm that can be implemented into the AlgorithmAnalysis.jl package.

The main contribution of this thesis is the development of a software package \texttt{AlgorithmAnalysis.jl} that similar to PESTO and PEPit aims to provide an accessible and fast way to analyze the performance of first-order methods for a guaranteed convergence rate using the Lyapunov function-based approach instead of PEP.

By developing a domain-specific language inside the Julia programming language, Algorithm Analysis simplifies the process of defining an optimization algorithm, provides a systemic way to represent abstract concepts such as algorithm iterate or the gradient of an abstract function, and make the analysis of optimization algorithms more accessible to non-expert users.

Implemented as a domain-specific language (DSL) embedded in Julia, texttt{AlgorithmAnalysis.jl} enables users to describe optimization algorithms at a high level while internally handles the mathematical complexity of worst-case performance analysis. By introducing a systematic representation of algorithmic components such as iterates, gradients, and function oracles, while automating the generation of interpolation conditions and the Lyapunov function optimization problem, the package lowers the barrier to entry for non-experts and promotes experimentation, rapid prototyping, and reproducible research in algorithm design.

