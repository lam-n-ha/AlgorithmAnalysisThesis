 \chapter{Literature Review}

In recent years, numerous studies have been conducted comparing the performance of optimization algorithms, particularly in machine learning and deep learning contexts. These comparisons often focus on convergence speed, accuracy, and robustness across various models and datasets. In \cite{adam}, Kingma and Ba presented the Adam (Adaptive Moment Estimation) algorithm. In order to prove its efficiency improvement above existing algorithms, the authors designed and conducted experiments where they are used to solve popular machine learning models and recorded the convergence rate of each. The result of these experiments provided emperical evidence that Adam performed better compared to its peers and gave a general idea of Adam's performance.

On the other hand, there exist in the literature approaches to performing algorithm analysis. In 2014, Drori and Teboulle first introduced the method of representing a class of function with constraints, reformulating the problem of analyzing an optimization method into a semidefinite program (SDP) whose size is proportionate with the number of iterations the algorithm is run.\cite{drori2012}. The paper coined the term Performance Estimation Problem (PEP) and showed that by solving a convex semidefinite problem (SDP), a worst-case numerical bound on an algorithm's performance solving that class of function can be derived. Taylor, Hendrickx and Glineur built upon this work by introducing the ideas of creating a finite representation for a class of smooth strongly convex functions using closed-form necessary and sufficient conditions. This work culminated in a way to perform algorithm analysis to derive the performance bound in the form of a guarantee that after a finxed number of iterates, how close the last iterate is to the goal.

In \cite{iqc}, Megretski and Rantzer demonstrated how integral quadratic constraints (IQCs) can be used to unify and simplify the analysis of system stability and performance. The paper shows how a complex system can be described using certain IQCs and presents a stability theorem for systems described by IQCs.

Computer programs have been developed to perform algorithm analysis using the PEP methods, which are PESTO \cite{pesto}, a MATLAB toolbox, and PEPit \cite{pepit}, a Python package. The program is able to perform algorithm analysis and generate a worst-case performance guarantee for algorithms and function classes from a supported list. PESTO and PEPit follows the PEP methodology and first presented an automatic way to analyze gradient-based algorithms.

JuPE implements the approach presented in \cite{tutorial}, which uses IQCs to represent the gradient of the algorithm and transforms the problem of deriving a performance guarantee to a convex SDP similar to the PEP approach. However, this approach instead uses Lyapunov functions to create a small and fixed size SDP, unlike that created by the PEP approach which grows in size for each iteration an algorithm is run, and proves that the performance measure inputted by the users decreases at a guaranteed rate throught out the optimizing process.

The main contribution of this thesis paper is to create a computer program named JuPE similar PESTO and PEPit that aims to provide an accessible and fast way to analyze the performance of first-order methods for a guaranteed convergence rate. By developing a domain-specific compiler inside the Julia programming language, JuPE simplifies the process of defining an optimization algorithm, provides a systemic way to represent abstract concepts such as algorithm iterate or the gradient of an abstract function, and make accessible the analysis of optimization algorithms. 